{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "UXqJRwEFDHzg",
    "outputId": "19c5253b-6739-41cc-de53-a4e2a1ef290f"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision import datasets\n",
    "from torch.utils.data import DataLoader\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load MNIST dataset\n",
    "# Definimos una secuencia de transformaciones para aplicar a las imágenes del dataset.\n",
    "# En este caso, solo convertimos las imágenes a tensores utilizando `ToTensor()`.\n",
    "# Esto es necesario para que las imágenes estén en un formato compatible con PyTorch.\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor()  # Convierte la imagen de un formato PIL o numpy.ndarray a un tensor.\n",
    "])\n",
    "\n",
    "# Cargamos el dataset MNIST de entrenamiento.\n",
    "# `root='./data'` especifica el directorio donde se descargarán los datos si no están presentes.\n",
    "# `train=True` indica que queremos el conjunto de datos de entrenamiento.\n",
    "# `transform=transform` aplica las transformaciones definidas previamente a cada imagen.\n",
    "# `download=True` descarga los datos si no están disponibles en el directorio especificado.\n",
    "mnist_dataset = datasets.MNIST(\n",
    "    root='./data', train=True, transform=transform, download=True\n",
    ")\n",
    "\n",
    "# Creamos un DataLoader que nos permite cargar los datos en lotes pequeños.\n",
    "# `dataset=mnist_dataset` es el dataset que se cargará.\n",
    "# `batch_size=16` indica que cada lote contendrá 16 imágenes y etiquetas.\n",
    "# `shuffle=True` mezcla los datos aleatoriamente en cada época, mejorando la generalización del modelo.\n",
    "data_loader = DataLoader(\n",
    "    mnist_dataset, batch_size=16, shuffle=True\n",
    ")\n",
    "\n",
    "# Obtenemos un único lote de datos del DataLoader.\n",
    "# `next(iter(data_loader))` convierte el DataLoader en un iterador y toma el primer lote.\n",
    "# El lote contiene `images` (los tensores de las imágenes) y `labels` (las etiquetas correspondientes).\n",
    "images, labels = next(iter(data_loader))\n",
    "\n",
    "#Por alguna razón esto siempre mata mi kernel, por l oque voy a comentarlo\n",
    "# Plot the images in a grid\n",
    "#plt.figure(figsize=(10, 10))\n",
    "#for i in range(16):\n",
    " #   plt.subplot(4, 4, i + 1)\n",
    "  #  plt.imshow(images[i].squeeze(), cmap='gray')\n",
    "   # plt.title(f'Label: {labels[i].item()}')\n",
    "    #plt.axis('off')\n",
    "#plt.tight_layout()\n",
    "#plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "experimentar neuronas por capa, capas ocultas y función de activación. Se modifica. Solo basta con número de neuronas o capas o la última"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Arquitectura"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "UT7LMM57CqC6",
    "outputId": "698dda5e-9c78-4a2a-b65b-8a22aec7eedc"
   },
   "outputs": [],
   "source": [
    "\n",
    "# Definimos el modelo MLP\n",
    "# MLP hereda de nn.Module, lo que permite utilizar las funciones y propiedades de PyTorch\n",
    "# para crear, entrenar y evaluar redes neuronales.\n",
    "class MLP(nn.Module):\n",
    "    def __init__(self):\n",
    "        # Inicializamos la clase base nn.Module\n",
    "        # Esto habilita funciones esenciales como la gestión de capas y forward pass.\n",
    "        super(MLP, self).__init__()\n",
    "        # Capa completamente conectada: de entrada (28x28 píxeles) a 512 neuronas\n",
    "        self.fc1 = nn.Linear(28 * 28, 400)\n",
    "        # Capa oculta: de 512 neuronas a 256 neuronas\n",
    "        self.fc2 = nn.Linear(400, 200)\n",
    "        # Capa de salida: de 256 neuronas a 10 clases (números del 0 al 9)\n",
    "        self.fc3 = nn.Linear(200, 10)\n",
    "        \n",
    "        #self.fc4 = nn.Linear(10, 10)\n",
    "        # Función de activación ReLU\n",
    "        self.relu = nn.ReLU()\n",
    "        self.leaky = nn.LeakyReLU()\n",
    "        self.sigmoid= nn.Sigmoid()\n",
    "\n",
    "        # Dropout para evitar sobreajuste\n",
    "        self.dropout = nn.Dropout(0.2)\n",
    "\n",
    "    # Definimos cómo pasa la información a través de la red\n",
    "    # Este método es obligatorio en las clases que heredan de nn.Module.\n",
    "    def forward(self, x):\n",
    "        x = x.view(-1, 28 * 28)  # Aplanamos las imágenes (de 28x28 a 1D)\n",
    "        x = self.relu(self.fc1(x))  # Aplicamos la primera capa y ReLU\n",
    "        x = self.dropout(x)         # Aplicamos Dropout\n",
    "        x = self.relu(self.fc2(x))  # Aplicamos la segunda capa y ReLU\n",
    "        x = self.dropout(x)         # Aplicamos Dropout\n",
    "        x = self.fc3(x)             # Aplicamos la capa de salida\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Entrenamiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Época [1/7], Pérdida: 0.4211\n",
      "Época [2/7], Pérdida: 0.1642\n",
      "Época [3/7], Pérdida: 0.0745\n",
      "Época [4/7], Pérdida: 0.0999\n",
      "Época [5/7], Pérdida: 0.1624\n",
      "Época [6/7], Pérdida: 0.0596\n",
      "Época [7/7], Pérdida: 0.0335\n",
      "El tiempo de ejecución del entrenamiento es: 42.932278 segundos\n"
     ]
    }
   ],
   "source": [
    "# Hiperparámetros\n",
    "batch_size = 128       # Tamaño de lote\n",
    "learning_rate = 0.001 # Tasa de aprendizaje\n",
    "epochs = 7           # Número de épocas de entrenamiento\n",
    "\n",
    "# Preprocesamiento y carga de datos de MNIST\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),                 # Convertimos imágenes a tensores\n",
    "    transforms.Normalize((0.5,), (0.5,))  # Normalizamos a media 0 y varianza 1\n",
    "])\n",
    "train_dataset = datasets.MNIST(\n",
    "    root='./data', train=True, transform=transform, download=True)  # Dataset de entrenamiento\n",
    "test_dataset = datasets.MNIST(\n",
    "    root='./data', train=False, transform=transform, download=True)  # Dataset de prueba\n",
    "train_loader = DataLoader(\n",
    "    dataset=train_dataset, batch_size=batch_size, shuffle=True)  # Dataloader para entrenamiento\n",
    "test_loader = DataLoader(\n",
    "    dataset=test_dataset, batch_size=batch_size, shuffle=False)  # Dataloader para prueba\n",
    "\n",
    "# Definimos el modelo, la función de pérdida y el optimizador\n",
    "model = MLP()                             # Creamos una instancia del modelo MLP\n",
    "criterion = nn.CrossEntropyLoss()         # Función de pérdida para clasificación\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)  # Optimizador Adam\n",
    "\n",
    "tiempo_inicial = time.time()\n",
    "\n",
    "# Bucle de entrenamiento\n",
    "for epoch in range(epochs):\n",
    "    model.train()  # Ponemos el modelo en modo entrenamiento\n",
    "    for images, labels in train_loader:  # Iteramos sobre lotes de datos\n",
    "        optimizer.zero_grad()            # Reiniciamos los gradientes\n",
    "        outputs = model(images)          # Hacemos una predicción con el modelo\n",
    "        loss = criterion(outputs, labels)  # Calculamos la pérdida\n",
    "        loss.backward()                  # Propagamos los gradientes\n",
    "        optimizer.step()                 # Actualizamos los pesos del modelo\n",
    "\n",
    "    # Mostramos la pérdida al final de cada época\n",
    "    print(f\"Época [{epoch+1}/{epochs}], Pérdida: {loss.item():.4f}\")\n",
    "\n",
    "tiempo_final = time.time()\n",
    "\n",
    "tiempo_transcurrido = tiempo_final - tiempo_inicial\n",
    "\n",
    "print(f\"El tiempo de ejecución del entrenamiento es: {tiempo_transcurrido:.6f} segundos\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluación del modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "id": "tTyHa34XCrxN"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy en el conjunto de prueba: 97.62%\n"
     ]
    }
   ],
   "source": [
    "model.eval()  # Ponemos el modelo en modo evaluación (desactiva Dropout)\n",
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():  # Desactivamos el cálculo de gradientes para evaluación\n",
    "    for images, labels in test_loader:  # Iteramos sobre los datos de prueba\n",
    "        outputs = model(images)         # Hacemos predicciones\n",
    "        _, predicted = torch.max(outputs.data, 1)  # Obtenemos la clase con mayor probabilidad\n",
    "        total += labels.size(0)         # Total de muestras evaluadas\n",
    "        correct += (predicted == labels).sum().item()  # Contamos las predicciones correctas\n",
    "\n",
    "# Calculamos y mostramos la precisión del modelo\n",
    "accuracy = 100 * correct / total\n",
    "print(f\"Accuracy en el conjunto de prueba: {accuracy:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Con la configuración predefinida el resultado de  accuracy es de un 97.73.\n",
    "\n",
    "1 experimento: modificar el número de neuronas por capa.\n",
    "#En los comentarios de la clase dice que la primera capa tiene 512, pero realmente son 200.\n",
    "capa 1:400\n",
    "capa 2:200\n",
    "Tiempo ejecución: 78.017469 segundos\n",
    "Resultado experimento neuronas 1: 97.69\n",
    "\n",
    "capa1: 600\n",
    "capa 2:300\n",
    "Tiempo ejecución: 322.068560 segundos\n",
    "Resultado experimento neuronas 2: 97.75\n",
    "Considerando el poco aumento con el aumento de neuronas, usaré el experimento 1 com obase para pasar al siguiente parámetro.\n",
    "\n",
    "Experimento función activacion 1:\n",
    "f=Leaky Relu en todas las capas ocultas.\n",
    "\n",
    "tiempo ejecución: 69.204278 segundos\n",
    "\n",
    "Resultado experimento funcion activacion 1: 97.51\n",
    "\n",
    "Experimento funcion activación 2:\n",
    "Agregamos una sigmoide a la capa de salida.\n",
    "\n",
    "Tiempo de ejecución: 69.204278 segundos\n",
    "Resultado experimento funciones de activación 2: 96.29. Es una mala idea agregar la sigmoide.\n",
    "\n",
    "El relu por defecto funciona bien.\n",
    "\n",
    "Experimento funciones de activación 3.\n",
    "Ponemos un relu en primera capa y leaky relu en la segunda.\n",
    "\n",
    "Tiempo de ejecución: 93.484747 segundos\n",
    "resultado: 97.40\n",
    "Si bien mejora el resultado sin la sigmoide, el mejor modelo sigue siendo de 2 capas, 400 y 200 neuronas y con función de activación relu. Si me queda tiempo probaré con otra capa."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Experimentos con el entrenamiento:\n",
    "Resultado con la estructura elegida en el paso anterior:97.77\n",
    "tiempo de ejecución: 93.484747 segundos\n",
    "\n",
    "experimento con algoritmo de optimización: Estandar Adam\n",
    "prueba:AdamW\n",
    "tiempo: 93.484747 segundos\n",
    "resultado:97.33\n",
    "\n",
    "Prueba con RMSprop.\n",
    "Tiempo de ejecución: 95.484747 segundos\n",
    "Resultado:97.38\n",
    "\n",
    "Con estos dos algoritmos, el mejor es el estandar Adam, por lo que lo conservaré de aquí en más.\n",
    "\n",
    "Tamaño del lote: Defecto 64.\n",
    "experimento 1: 48\n",
    "Tiempo de ejecución: 619.019119 segundos\n",
    "Resultado: 97.76\n",
    " \n",
    " Experimento 2: 80\n",
    " Tiempo de ejecución:71.038557 segundos\n",
    " Resultado: 97.95\n",
    "\n",
    "Experimento 3: 128\n",
    "Tiempo de ejecución: 61.631050 segundos\n",
    "Resultado: 97.84\n",
    " \n",
    " Experimento 4: 100\n",
    " Tiempo ejecución: 65.367842 segundos\n",
    " Resultado: 97.57\n",
    "\n",
    " Me quedo con el lote de 80, Si bien está por sobre los 10 segundos del modelo más eficiente, alcanza un mayor accuracy con el lote de 80. En este contexto prefiero privilegiar la accuracy, aunque en desafíos más grandes es probable que eligiera al eficiencia.\n",
    "\n",
    "experimento épocas.\n",
    "\n",
    "estandar 10:\n",
    "\n",
    "Prueba 15\n",
    "Tiempo de ejecución: 91.781324 segundos\n",
    "Resultado: 97.95\n",
    "\n",
    "\n",
    "Experimento 7\n",
    "Tiempo de ejecución: 42.932278 segundos\n",
    "Resultado:97.62\n",
    "\n",
    "Si bien el resultado de las 7 épocas es aceptable y demora la mitad del de 15 épocas, creo que las 10 épocas estandar son el equilibrio entre accuracy y tiempo de ejecución."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Probamos la red neuronal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verificar si hay una GPU disponible, de lo contrario usar la CPU\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Preprocesamiento: Definir transformaciones para los datos\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),                # Convertir imágenes a tensores\n",
    "    transforms.Normalize((0.5,), (0.5,))  # Normalizar los valores a un rango de [-1, 1]\n",
    "])\n",
    "\n",
    "# Cargar el conjunto de datos MNIST\n",
    "train_dataset = datasets.MNIST(root='./data', train=True, transform=transform, download=True)  # Datos de entrenamiento\n",
    "test_dataset = datasets.MNIST(root='./data', train=False, transform=transform, download=True)  # Datos de prueba\n",
    "\n",
    "# Crear DataLoaders para manejar los datos de forma eficiente\n",
    "train_loader = DataLoader(train_dataset, batch_size=128, shuffle=True)   # Loader para entrenamiento (batch de 128, mezclado)\n",
    "test_loader = DataLoader(test_dataset, batch_size=128, shuffle=False)    # Loader para prueba (batch de 128, sin mezclar)\n",
    "\n",
    "class CNN(nn.Module):\n",
    "    def __init__(self, verbose=False, filters_l1=32, filters_l2=64, dropout=0.2, final_layer_size=128):\n",
    "        super(CNN, self).__init__()\n",
    "        self.verbose = verbose\n",
    "        self.filters_l1 = filters_l1\n",
    "        self.filters_l2 = filters_l2\n",
    "        self.dropout_rate = dropout\n",
    "        self.final_layer_size = final_layer_size\n",
    "\n",
    "        # Primera capa convolucional\n",
    "        self.conv1 = nn.Conv2d(1, self.filters_l1, kernel_size=3, stride=1, padding=1)\n",
    "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "\n",
    "        # Segunda capa convolucional\n",
    "        self.conv2 = nn.Conv2d(self.filters_l1, self.filters_l2, kernel_size=3, stride=1, padding=1)\n",
    "\n",
    "        # Calcular automáticamente las dimensiones de la capa lineal (fc1)\n",
    "        self.fc1_input_size = self._calculate_fc1_input_size()\n",
    "        \n",
    "        # Primera capa completamente conectada\n",
    "        self.fc1 = nn.Linear(self.fc1_input_size, self.final_layer_size)\n",
    "        self.dropout = nn.Dropout(self.dropout_rate)\n",
    "        self.fc2 = nn.Linear(self.final_layer_size, 10)  # Capa de salida para 10 clases (MNIST)\n",
    "\n",
    "    def _calculate_fc1_input_size(self):\n",
    "        \"\"\"\n",
    "        Calcula automáticamente el tamaño de la entrada para la primera capa completamente conectada (fc1).\n",
    "        Simula una pasada con una imagen de prueba de tamaño (1, 28, 28).\n",
    "        \"\"\"\n",
    "        with torch.no_grad():  # Desactiva gradientes\n",
    "            x = torch.randn(1, 1, 28, 28)  # Tensor ficticio de entrada con tamaño MNIST (batch_size=1)\n",
    "            x = self.pool(torch.relu(self.conv1(x)))  # Aplicar Conv1 -> Pool\n",
    "            x = self.pool(torch.relu(self.conv2(x)))  # Aplicar Conv2 -> Pool\n",
    "            fc1_input_size = x.numel()  # Calcular número total de elementos\n",
    "        return fc1_input_size\n",
    "\n",
    "    def forward(self, x):\n",
    "        if self.verbose: \n",
    "            print(f\"Entrada: {x.shape}\")  # Imprime la dimensión de la entrada\n",
    "\n",
    "        # Primera capa convolucional, ReLU y MaxPooling\n",
    "        x = self.pool(torch.relu(self.conv1(x)))\n",
    "        if self.verbose:\n",
    "            print(f\"Después de Conv1 y MaxPooling: {x.shape}\")  # Dimensión después de Conv1 y Pool\n",
    "\n",
    "        # Segunda capa convolucional, ReLU y MaxPooling\n",
    "        x = self.pool(torch.relu(self.conv2(x)))\n",
    "        if self.verbose:\n",
    "            print(f\"Después de Conv2 y MaxPooling: {x.shape}\")  # Dimensión después de Conv2 y Pool\n",
    "\n",
    "        # Aplanar las características 2D a 1D\n",
    "        x = x.view(-1, self.fc1_input_size)\n",
    "        if self.verbose:\n",
    "            print(f\"Después de Aplanamiento: {x.shape}\")  # Dimensión después de Flatten\n",
    "\n",
    "        # Primera capa completamente conectada\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        if self.verbose:\n",
    "            print(f\"Después de Fully Connected (fc1): {x.shape}\")  # Dimensión después de fc1\n",
    "\n",
    "        # Aplicar Dropout\n",
    "        x = self.dropout(x)\n",
    "        if self.verbose:\n",
    "            print(f\"Después de Dropout: {x.shape}\")  # Dimensión después de Dropout\n",
    "\n",
    "        # Capa de salida\n",
    "        x = self.fc2(x)\n",
    "        if self.verbose:\n",
    "            print(f\"Después de Fully Connected (fc2): {x.shape}\")  # Dimensión después de fc2 (salida final)\n",
    "\n",
    "        return x\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/10], Loss: 0.2114, Test Accuracy: 0.9852\n",
      "Epoch [2/10], Loss: 0.0589, Test Accuracy: 0.9879\n",
      "Epoch [3/10], Loss: 0.0399, Test Accuracy: 0.9899\n",
      "Epoch [4/10], Loss: 0.0292, Test Accuracy: 0.9905\n",
      "Epoch [5/10], Loss: 0.0225, Test Accuracy: 0.9917\n",
      "Epoch [6/10], Loss: 0.0190, Test Accuracy: 0.9894\n",
      "Epoch [7/10], Loss: 0.0158, Test Accuracy: 0.9929\n",
      "Epoch [8/10], Loss: 0.0129, Test Accuracy: 0.9913\n",
      "Epoch [9/10], Loss: 0.0112, Test Accuracy: 0.9909\n",
      "Epoch [10/10], Loss: 0.0090, Test Accuracy: 0.9913\n",
      "El tiempo de ejecución del entrenamiento neuronal es: 140.757827 segundos\n",
      "Final Test Accuracy: 0.9913\n"
     ]
    }
   ],
   "source": [
    "# Inicializar el modelo, la función de pérdida y el optimizador\n",
    "\n",
    "\n",
    "model = CNN(verbose=False, filters_l1=16, filters_l2=64, dropout=0.2, final_layer_size=128).to(device)                             # Mover el modelo a la GPU/CPU\n",
    "criterion = nn.CrossEntropyLoss()                    # Función de pérdida para clasificación multiclase\n",
    "optimizer = optim.RMSprop(model.parameters(), lr=0.001) # Optimizador Adam con tasa de aprendizaje 0.001\n",
    "\n",
    "# Definir la función de entrenamiento\n",
    "def train(model, loader, criterion, optimizer, device):\n",
    "    model.train()  # Establecer el modelo en modo de entrenamiento\n",
    "    running_loss = 0.0\n",
    "    for images, labels in loader:  # Iterar sobre los lotes de datos\n",
    "        images, labels = images.to(device), labels.to(device)  # Mover los datos a la GPU/CPU\n",
    "\n",
    "        optimizer.zero_grad()       # Reiniciar los gradientes\n",
    "        outputs = model(images)     # Paso hacia adelante\n",
    "        loss = criterion(outputs, labels)  # Calcular la pérdida\n",
    "        loss.backward()             # Paso hacia atrás (cálculo de gradientes)\n",
    "        optimizer.step()            # Actualizar los pesos\n",
    "\n",
    "        running_loss += loss.item()  # Acumular la pérdida\n",
    "    return running_loss / len(loader)  # Devolver la pérdida promedio\n",
    "\n",
    "# Definir la función de evaluación\n",
    "def evaluate(model, loader, device):\n",
    "    model.eval()  # Establecer el modelo en modo de evaluación\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():  # Deshabilitar el cálculo de gradientes para ahorrar memoria\n",
    "        for images, labels in loader:\n",
    "            images, labels = images.to(device), labels.to(device)  # Mover datos a la GPU/CPU\n",
    "            outputs = model(images)  # Paso hacia adelante\n",
    "            _, predicted = torch.max(outputs, 1)  # Obtener las predicciones (clase con mayor probabilidad)\n",
    "            total += labels.size(0)  # Contar el número total de ejemplos\n",
    "            correct += (predicted == labels).sum().item()  # Contar las predicciones correctas\n",
    "    return correct / total  # Calcular la precisión\n",
    "\n",
    "# Bucle principal de entrenamiento\n",
    "num_epochs = 10  # Número de épocas\n",
    "\n",
    "tiempo_inicial2 = time.time()\n",
    "for epoch in range(num_epochs):\n",
    "    # Entrenar el modelo y calcular la pérdida\n",
    "    train_loss = train(model, train_loader, criterion, optimizer, device)\n",
    "    # Evaluar el modelo en el conjunto de prueba\n",
    "    test_accuracy = evaluate(model, test_loader, device)\n",
    "    # Imprimir los resultados de la época actual\n",
    "    print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {train_loss:.4f}, Test Accuracy: {test_accuracy:.4f}\")\n",
    "\n",
    "\n",
    "\n",
    "tiempo_final2 = time.time()\n",
    "\n",
    "tiempo_transcurrido2 = tiempo_final2 - tiempo_inicial2\n",
    "\n",
    "print(f\"El tiempo de ejecución del entrenamiento neuronal es: {tiempo_transcurrido2:.6f} segundos\")\n",
    "\n",
    "# Calcular la precisión final en el conjunto de prueba\n",
    "final_accuracy = evaluate(model, test_loader, device)\n",
    "print(f\"Final Test Accuracy: {final_accuracy:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "experimentos red neuronal:\n",
    "\n",
    "Probamos los valores predefinidos:\n",
    "Tiempo de ejecución: 125.909052 segundos\n",
    "Resultado:0.9902\n",
    "\n",
    "Vamos a empezar con los filtros, subiré a 16 y 64. Por lo que dice la documentación esto no conviene en tareas de este tipo, pero la documentación puede decir lo que uqiera jj.\n",
    "Prueba (16, 64)\n",
    "Tiempo de ejecución: 150.085726 segundos\n",
    "resultado:0.9933\n",
    "\n",
    "Prueba (32, 128) Creo que es volar muy cerca de lsol, pero veremos que pasa.\n",
    "Tiempo de ejecución: 243.019903 segundos\n",
    "Resultado:0.9915\n",
    "Creo que es obvio que llegamos a un punto muerto. 16 y 64 es lo mejor que podemos conseguir en esto, tanto por tiempo de ejecución como por aumento del accuracy. Aunque por estandar no está mal considerando que demora 30 segundos menos.\n",
    "\n",
    "experimento capa luego de convolución: Estandar 128\n",
    "prueba: 192\n",
    "Tiempo de ejecución: 159.389823 segundos\n",
    "Resultado: 0.9917\n",
    "Creo que sesobreajusta por cantidad de neuronas, igual probaré con 256 a ver que pasa.\n",
    "\n",
    "prueba: 256.\n",
    "tiempo de ejecución: 165.243595 segundos\n",
    "Resultado:0.9897\n",
    "Efectivamente se sobreajusta por muchas neuronas. Probaré con 64 a ver que pasa, pero al parecer 128 es el número.\n",
    "\n",
    "prueba 64:\n",
    "Tiempo de ejecución:140.146199 segundos\n",
    "resultado:0.9918\n",
    "Parecido a 192, pero con algunos segundos menos en la ejecución. No está mal, pero me quedo con 128.\n",
    "\n",
    "Experimentos  dropout: Estandar 0.2\n",
    "\n",
    "prueba 0.4\n",
    "Tiempo de ejecución: 249.527926 segundos\n",
    "Resultado:0.9912\n",
    "\n",
    "Prueba 0.5:\n",
    "Tiempo de ejecución:144.139868 segundos\n",
    "Resultado:0.9910\n",
    "El aumento no es la respuesta. Probaré con 0.3 a ver que pasa. Aunque hay que admitir que este segundo experimento tardó mucho menos que el otro.\n",
    "\n",
    "Prueba 0.3.\n",
    "Tiempo de ejecución: 152.109582 segundos\n",
    "Resultado:0.9920\n",
    "Tenía que ocurrir un aumento, considerando que las anteriores estuvieron cerca del 0.9910. Solo para terminar voy a probar con 0.1.\n",
    "\n",
    "Prueba 0.1:\n",
    "Tiempo de ejecución:146.884606 segundos\n",
    "Resultado: 0.9920\n",
    "Me quedo con 0.2. Los demás no están mal, pero 0.2 es mejor.\n",
    "\n",
    "#Conclusión estructura: la mejor combinación es filtros (16, 64), dropout: 0.2 y capas luego de convolución=128.\n",
    "\n",
    "Prueba con entrenamiento.\n",
    "\n",
    "Algoritmo base: Adam.\n",
    "\n",
    "Prueba Learning rate: estandar: 0.001\n",
    "\n",
    "Prueba 0.01\n",
    "Tiempo de ejecución: 157.241732 segundos\n",
    "Resultado:0.9644\n",
    "Si subiendo un orden el resultado bajó considerablemente, creo inoficioso probar con otros números. Cambiaré de algoritmo y cerraré.\n",
    "\n",
    "ALgoritmos:\n",
    "prueba:AdamW con lr de 0.001\n",
    "Tiempo de ejecución: 394.762783 segundos\n",
    "Resultado: 0.9905\n",
    "Demora mucho y no mejora. Descartado.\n",
    "\n",
    "Prueba RMSprop\n",
    "\n",
    "Tiempo ejecución:140.757827 segundos\n",
    "Resultado:0.9913\n",
    "Alcanza un rendimiento bastante alto en la mitad de las épocas, pero tampoco supera al lagoritmo Adam. Creo que lo estandar fucniona bien.\n",
    "\n",
    "Se probaron varios algoritmos y el mejor es Adam con un lr de 0.001.\n",
    "\n",
    "Síntesis gneeral: para los experimentos, el hiperparámetro más relevante fue aumentar los filtros de la 1 y 2 capa. Eso consigue un modelo cuyo rendimiento es algo mejor que la configuración estandar. En cuanto al tiempo, los resultados suelen estar entre 140 y 160 segundos. La mejor accuracy se logra en 150 segundos, siendo el experimento de los filtros. El resto se mueve por ahí, pero con menro accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Conclusión:\n",
    "\n",
    "Como puede observarse, la red convolucional tiene mucho mejor rendimiento que el perceptrón. Esto no es de sorprender si consideramos que la documentación señala que la neuronal convolucional es precisamente para utilizar en estos casos, mientras que el perceptrón está pensado en propósitos tabulares y numéricos de otro tipo. AUnque también obtiene resultados bastante buenos, solo que la red convolucional es mejor.\n",
    "Lo que más modificó el resultado del perceptrón fue el cambio en las neuronas de las cpaas, pasando de 200 a 400 en al primera y de 256 a 200 en la segunda. Mientras que para la red convolucional fueron los filtros, pasando de 8 a 16 en la primera capa y de 32 a 64 en la segunda. El dropout y el número de neuronas en la capa final no fueron determinantes en aumentar el rendimiento.\n",
    "\n",
    "En síntesis, la mejor elección para problemas de este tipo es la red neuronal convolucional, poniendo especial atención en los filtros de las capas. Finalmente, la red neuronal demora dos veces y media el tiempo que el perceptrón en obtener su mejor resultado, 0.9933 en 150 segundos, mientras que el 97.84 del perceptrón se obtuvo en 61 segundos. Aún con esto sigo prefiriendo la red neuronal."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
